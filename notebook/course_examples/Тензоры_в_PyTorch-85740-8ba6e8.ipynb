{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba5b69af",
      "metadata": {
        "id": "ba5b69af"
      },
      "source": [
        "# Тензоры в PyTorch\n",
        "\n",
        "[*Тензор*](https://pytorch.org/docs/stable/tensors.html) - специализированная структура данных наподобие матриц и массивов.\n",
        "\n",
        "В *PyTorch* тензоры хранят входные и выходные данные моделей, а также их параметры (веса)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490d0979",
      "metadata": {
        "id": "490d0979"
      },
      "source": [
        "#### Установка PyTorch 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как понять какой PyTorch нужен?\n",
        "https://pytorch.org/get-started/locally/"
      ],
      "metadata": {
        "id": "Ryu0fE1XrA4c"
      },
      "id": "Ryu0fE1XrA4c"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b5eb4e12",
      "metadata": {
        "id": "b5eb4e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae8d30c-4b3a-4215-ef63-09f6b1a10875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# PyTorch 2.x + платформа параллельных вычислений NVIDIA CUDA (11.8):\n",
        "# ! pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# # PyTorch 2.x + CUDA 12.4:\n",
        "! pip3 install torch torchvision --pre --index-url https://download.pytorch.org/whl/nightly/cu124"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3c2fdbb",
      "metadata": {
        "id": "e3c2fdbb"
      },
      "source": [
        "#### Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "374c41a9",
      "metadata": {
        "id": "374c41a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a5ded692-1c8f-490e-e6f0-0aeb711dc655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "print (torch.cuda.is_available())\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acfad3b2",
      "metadata": {
        "id": "acfad3b2"
      },
      "source": [
        "### 1. Инициализация тензоров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "711b9c2a",
      "metadata": {
        "id": "711b9c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09966e96-8ca9-45e7-b55b-1da593f64d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3], [4, 5, 6], [7, 8, 9]] \n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Инициализация из структуры (напишите в чат, что это за структура):\n",
        "my_data = [[1,2,3], [4,5,6], [7,8,9]]\n",
        "print (my_data, '\\n')\n",
        "\n",
        "my_tensor = torch.tensor(my_data, device='cuda:0')\n",
        "print (my_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c1385e23",
      "metadata": {
        "id": "c1385e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f17a806-2240-4b44-857d-f4bc127148a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]] \n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "# Инициализация из NymPy array:\n",
        "np_array = np.array(my_data)\n",
        "print (np_array, '\\n')\n",
        "\n",
        "my_tensor = torch.from_numpy(np_array)\n",
        "print (my_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# перенос на другое устройство (вариант 1)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = my_tensor.cuda()  # Переносим тензор на GPU\n",
        "    print(\"Тензор на GPU:\", tensor_gpu)\n",
        "else:\n",
        "    print(\"Found no NVIDIA driver on your system\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlbxfcQrLf4_",
        "outputId": "a7f4a49d-b47f-45e4-98dd-5688cea08da3"
      },
      "id": "wlbxfcQrLf4_",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тензор на GPU: tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "507fac3b",
      "metadata": {
        "id": "507fac3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a419a681-e4df-4c00-d711-3c0606ac7875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]]) \n",
            "\n",
            "tensor([[0.9292, 0.9286, 0.9671],\n",
            "        [0.7810, 0.4197, 0.2444],\n",
            "        [0.1424, 0.5716, 0.7235]])\n"
          ]
        }
      ],
      "source": [
        "# Инициализация из другого тензора:\n",
        "my_ones = torch.ones_like(my_tensor) # свойства сохраняются\n",
        "print(my_ones, '\\n')\n",
        "\n",
        "my_rand = torch.rand_like(my_tensor, dtype=torch.float) # переопределяем тип хранимых данных\n",
        "print(my_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dca94ce3",
      "metadata": {
        "id": "dca94ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73e55e3-21c7-4549-e558-1417d625221e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1079, 0.7088, 0.9294, 0.4571, 0.9355, 0.8818],\n",
            "        [0.5424, 0.4053, 0.0429, 0.3074, 0.9383, 0.4774],\n",
            "        [0.3672, 0.7774, 0.5423, 0.3465, 0.0732, 0.4514],\n",
            "        [0.2426, 0.7264, 0.4174, 0.1774, 0.6644, 0.7252]])\n",
            "tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Инициализация с определением размерности тензора:\n",
        "shape = (4,6,)\n",
        "print (torch.rand(shape))\n",
        "print (torch.ones(shape))\n",
        "print (torch.zeros(shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91534a9d",
      "metadata": {
        "id": "91534a9d"
      },
      "source": [
        "### 2. Атрибуты тензоров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2797a20d",
      "metadata": {
        "id": "2797a20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdad2420-bce7-4208-aa5a-8a5c3f9e6cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма (размерность): torch.Size([3, 4, 5, 6])\n",
            "Тип данных: torch.float32\n",
            "Девайс где хранятся данные: cpu\n"
          ]
        }
      ],
      "source": [
        "my_tensor = torch.rand(3,4,5,6)\n",
        "\n",
        "print(f\"Форма (размерность): {my_tensor.shape}\")\n",
        "print(f\"Тип данных: {my_tensor.dtype}\")\n",
        "print(f\"Девайс где хранятся данные: {my_tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e59397",
      "metadata": {
        "id": "75e59397"
      },
      "source": [
        "### 3. Операции над тензорами\n",
        "[Список операций в PyTorch](https://pytorch.org/docs/stable/torch.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "87515f17",
      "metadata": {
        "id": "87515f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c4516f-f933-44ba-e9ec-d057cdb2fd56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1410, 0.9311, 0.5417, 0.4208],\n",
            "        [0.3863, 0.5832, 0.1885, 0.6960],\n",
            "        [0.1198, 0.3887, 0.6518, 0.0404]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Перемещаем тензор на GPU:\n",
        "my_tensor = torch.rand(size=(3,4))\n",
        "if torch.cuda.is_available():\n",
        "    my_tensor = my_tensor.to(\"cuda:0\")\n",
        "    print (my_tensor)\n",
        "else: print('Found no NVIDIA driver on your system')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# my_tensor.cuda()"
      ],
      "metadata": {
        "id": "keuVX8TdSpZ-"
      },
      "id": "keuVX8TdSpZ-",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9b37fdcd",
      "metadata": {
        "id": "9b37fdcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58629612-77a4-4f90-8d9c-7a24ad056e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первая строка: tensor([0.1410, 0.9311, 0.5417, 0.4208], device='cuda:0')\n",
            "Первый столбец: tensor([0.1410, 0.3863, 0.1198], device='cuda:0')\n",
            "Последний столбец: tensor([0.4208, 0.6960, 0.0404], device='cuda:0')\n",
            "tensor([[0.1410, 0.0000, 0.5417, 0.4208],\n",
            "        [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "        [0.1198, 0.0000, 0.6518, 0.0404]])\n"
          ]
        }
      ],
      "source": [
        "# Операции indexing и slicing:\n",
        "print(f\"Первая строка: {my_tensor[0]}\")\n",
        "print(f\"Первый столбец: {my_tensor[:, 0]}\")\n",
        "print(f\"Последний столбец: {my_tensor[..., -1]}\")\n",
        "\n",
        "my_tensor = my_tensor.to(\"cpu\") # еще вариант переноса\n",
        "my_tensor[:,1] = 0     # присваиваем константу 0 второму столбцу\n",
        "print (my_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sItIyFlNAv3",
        "outputId": "662434de-9edc-4b86-c558-4c8f7a5f0af4"
      },
      "id": "0sItIyFlNAv3",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Конкатенация тензоров (объединение по существующему измерению):\n",
        "cat_tensor = torch.cat([my_tensor, my_tensor, my_tensor], dim=0)\n",
        "print(cat_tensor.shape)\n",
        "print(cat_tensor)\n",
        "\n",
        "# Стекинг тензоров (объединение в новом измерении):\n",
        "stack_tensor = torch.stack([my_tensor, my_tensor, my_tensor])\n",
        "print(stack_tensor.shape)\n",
        "print(stack_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZw3s4ZKNw4X",
        "outputId": "1b8954ab-d4eb-479e-a3a5-a54c62bca092"
      },
      "id": "oZw3s4ZKNw4X",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 4])\n",
            "tensor([[0.1410, 0.0000, 0.5417, 0.4208],\n",
            "        [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "        [0.1198, 0.0000, 0.6518, 0.0404],\n",
            "        [0.1410, 0.0000, 0.5417, 0.4208],\n",
            "        [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "        [0.1198, 0.0000, 0.6518, 0.0404],\n",
            "        [0.1410, 0.0000, 0.5417, 0.4208],\n",
            "        [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "        [0.1198, 0.0000, 0.6518, 0.0404]])\n",
            "torch.Size([3, 3, 4])\n",
            "tensor([[[0.1410, 0.0000, 0.5417, 0.4208],\n",
            "         [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "         [0.1198, 0.0000, 0.6518, 0.0404]],\n",
            "\n",
            "        [[0.1410, 0.0000, 0.5417, 0.4208],\n",
            "         [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "         [0.1198, 0.0000, 0.6518, 0.0404]],\n",
            "\n",
            "        [[0.1410, 0.0000, 0.5417, 0.4208],\n",
            "         [0.3863, 0.0000, 0.1885, 0.6960],\n",
            "         [0.1198, 0.0000, 0.6518, 0.0404]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Арифметические операции - перемножение матриц:\n",
        "y1 = my_tensor @ my_tensor.T\n",
        "y2 = my_tensor.matmul(my_tensor.T)\n",
        "y3 = torch.rand_like(my_tensor)\n",
        "torch.matmul(my_tensor, my_tensor.T, out=y3)\n",
        "print ('y1:', y1,'\\ny2:', y2,'\\ny3:',y3)"
      ],
      "metadata": {
        "id": "g_z9MKK6uV0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc24b3c-8908-46bc-8dd3-b092b56fdb08"
      },
      "id": "g_z9MKK6uV0p",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1: tensor([[0.4904, 0.4494, 0.3870],\n",
            "        [0.4494, 0.6692, 0.1973],\n",
            "        [0.3870, 0.1973, 0.4409]]) \n",
            "y2: tensor([[0.4904, 0.4494, 0.3870],\n",
            "        [0.4494, 0.6692, 0.1973],\n",
            "        [0.3870, 0.1973, 0.4409]]) \n",
            "y3: tensor([[0.4904, 0.4494, 0.3870],\n",
            "        [0.4494, 0.6692, 0.1973],\n",
            "        [0.3870, 0.1973, 0.4409]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ef30bf4498d2>:5: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [3, 3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /pytorch/aten/src/ATen/native/Resize.cpp:30.)\n",
            "  torch.matmul(my_tensor, my_tensor.T, out=y3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3232cd14",
      "metadata": {
        "id": "3232cd14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60061c4d-5673-440e-a0b8-6ff48fad1df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z1: tensor([[0.0199, 0.0000, 0.2935, 0.1770],\n",
            "        [0.1492, 0.0000, 0.0355, 0.4844],\n",
            "        [0.0143, 0.0000, 0.4249, 0.0016]]) \n",
            "z2: tensor([[0.0199, 0.0000, 0.2935, 0.1770],\n",
            "        [0.1492, 0.0000, 0.0355, 0.4844],\n",
            "        [0.0143, 0.0000, 0.4249, 0.0016]]) \n",
            "z3: tensor([[0.0199, 0.0000, 0.2935, 0.1770],\n",
            "        [0.1492, 0.0000, 0.0355, 0.4844],\n",
            "        [0.0143, 0.0000, 0.4249, 0.0016]])\n"
          ]
        }
      ],
      "source": [
        "# Арифметические операции - поэлементное перемножение:\n",
        "z1 = my_tensor * my_tensor\n",
        "z2 = my_tensor.mul(my_tensor)\n",
        "z3 = torch.rand_like(my_tensor)\n",
        "torch.mul(my_tensor, my_tensor, out=z3)\n",
        "print ('z1:', z1,'\\nz2:', z2,'\\nz3:',z3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Одноэлементные тензоры (скаляр):\n",
        "result = my_tensor.sum()         # суммируем все элементы тензора\n",
        "value = result.item()            # приводим тензор к Python numerical value\n",
        "print(value, type(value), result, type(result))\n",
        "\n",
        "result = my_tensor.mean()        # среднее по всем элементам тензора\n",
        "print(result.item())\n",
        "\n",
        "result = my_tensor.mean(dim=1)   # среднее по 1 измерению\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7rQvDqkPTwo",
        "outputId": "593566e6-7ab7-4977-d48f-136f384d7e8f"
      },
      "id": "N7rQvDqkPTwo",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1862635612487793 <class 'float'> tensor(3.1863) <class 'torch.Tensor'>\n",
            "0.26552197337150574\n",
            "tensor([0.2759, 0.3177, 0.2030])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5554b38",
      "metadata": {
        "id": "c5554b38"
      },
      "source": [
        "### 4. PyTorch тензоры и NumPy массивы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3c68280d",
      "metadata": {
        "id": "3c68280d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482f32a1-ed1f-4d2a-be71-011b929e29e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1., -6.,  1.,  1.,  1.]) torch.Size([5]) torch.float32\n",
            "[ 1. -6.  1.  1.  1.] (5,) float32\n"
          ]
        }
      ],
      "source": [
        "# Tensor -> NumPy array:\n",
        "t = torch.ones(5, device='cpu')\n",
        "n = t.numpy()\n",
        "\n",
        "t[1] = -6\n",
        "print(t, t.shape, t.dtype)\n",
        "print(n, n.shape, n.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6a208bae",
      "metadata": {
        "id": "6a208bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c286b8-d687-43dd-df6f-a8db7700fe92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8., 1., 8., 8., 8.], dtype=torch.float64) torch.Size([5]) torch.float64\n",
            "[8. 1. 8. 8. 8.] (5,) float64\n"
          ]
        }
      ],
      "source": [
        "# NumPy array -> Tensor:\n",
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "\n",
        "t[1] = -6\n",
        "n = np.add(n, 7, out=n)\n",
        "print(t, t.shape, t.dtype)\n",
        "print(n, n.shape, n.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Самостоятельное задание:\n",
        "ниже приведено два тензора. Необходимо взять квадратный корень поэлементно с каждого массива, затем поэлементно перемножить и найти стандартное отклонение"
      ],
      "metadata": {
        "id": "VdvWf9nBiUo1"
      },
      "id": "VdvWf9nBiUo1"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "array1 = torch.tensor([1, 2, 3])\n",
        "array2 = torch.tensor([[4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])"
      ],
      "metadata": {
        "id": "yKiyL09piUEt"
      },
      "id": "yKiyL09piUEt",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res= torch.mul(array1.to(torch.float).sqrt_(), array2.sqrt_()).std().item()\n",
        "res"
      ],
      "metadata": {
        "id": "6ROiBvF1P0Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33164d10-5121-4d78-83d3-b340399885e3"
      },
      "id": "6ROiBvF1P0Vw",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1629352569580078"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zi6WOnJWRPmS"
      },
      "id": "Zi6WOnJWRPmS",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Аппроксимация функции y=sin(x) полиномом третьего порядка (NumPy vs PyTorch vs PyTorch NN)"
      ],
      "metadata": {
        "id": "FJuMcIOlRQ44"
      },
      "id": "FJuMcIOlRQ44"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Создаем датасет (x - входные данные, y - результат):\n",
        "x = np.linspace(-math.pi, math.pi, 2000)\n",
        "y = np.sin(x)\n",
        "\n",
        "# Инициализируем коэффициенты нашего полинома случайными значениями (выполняют роль весов модели):\n",
        "a = np.random.randn()\n",
        "b = np.random.randn()\n",
        "c = np.random.randn()\n",
        "d = np.random.randn()\n",
        "\n",
        "# Скорость обучения:\n",
        "learning_rate = 1e-6\n",
        "\n",
        "# Оптимизационный цикл (цикл обучения):\n",
        "for t in range(2500):\n",
        "\n",
        "    # Прямой проход: вычисляем предсказанный y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Считаем ошибку (MSE) предскзанного y_pred и истинного y:\n",
        "    loss = np.square(y_pred - y).mean()\n",
        "    if t % 100 == 99:\n",
        "        print(f'iter={t}, loss={loss}')\n",
        "\n",
        "    # Обратный проход (вычисляем градиенты для a, b, c, d относительно loss):\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Обновляем коэффициенты полинома (веса) с учетом расчитанного градиента:\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc0djlhWTluJ",
        "outputId": "2a23ea19-829b-4dfd-e762-8e07f94beb0e"
      },
      "id": "Bc0djlhWTluJ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter=99, loss=0.39777171768877256\n",
            "iter=199, loss=0.27623738892732863\n",
            "iter=299, loss=0.19244727513271478\n",
            "iter=399, loss=0.13461696432739506\n",
            "iter=499, loss=0.09466124753995943\n",
            "iter=599, loss=0.06702660252152315\n",
            "iter=699, loss=0.04789415240604657\n",
            "iter=799, loss=0.034634915462773024\n",
            "iter=899, loss=0.025437058801953183\n",
            "iter=999, loss=0.019050552843810364\n",
            "iter=1099, loss=0.014612049284792466\n",
            "iter=1199, loss=0.011524641262681162\n",
            "iter=1299, loss=0.00937521250455323\n",
            "iter=1399, loss=0.007877560816052752\n",
            "iter=1499, loss=0.006833214923757618\n",
            "iter=1599, loss=0.006104411072052467\n",
            "iter=1699, loss=0.005595435796196613\n",
            "iter=1799, loss=0.005239731198164718\n",
            "iter=1899, loss=0.004990973698914516\n",
            "iter=1999, loss=0.004816895614806109\n",
            "iter=2099, loss=0.0046950020635353395\n",
            "iter=2199, loss=0.004609598927527322\n",
            "iter=2299, loss=0.004549728635855112\n",
            "iter=2399, loss=0.004507735171333775\n",
            "iter=2499, loss=0.004478265625331504\n",
            "Result: y = 0.011862940217502432 + 0.8531350062805678 x + -0.002046554587696451 x^2 + -0.09281749015666683 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "переходим на PyTorch"
      ],
      "metadata": {
        "id": "orQOwlZ8T96g"
      },
      "id": "orQOwlZ8T96g"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Выбираем устройства для вычислений:\n",
        "# device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda:0\") # запускаем на GPU\n",
        "\n",
        "# Создаем датасет (x - входные данные, y - результат):\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=torch.float32)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Инициализируем коэффициенты нашего полинома случайными значениями (выполняют роль весов модели):\n",
        "a = torch.randn((), device=device, dtype=torch.float32)\n",
        "b = torch.randn((), device=device, dtype=torch.float32)\n",
        "c = torch.randn((), device=device, dtype=torch.float32)\n",
        "d = torch.randn((), device=device, dtype=torch.float32)\n",
        "\n",
        "# Скорость обучения:\n",
        "learning_rate = 1e-6\n",
        "\n",
        "\n",
        "# Оптимизационный цикл (цикл обучения):\n",
        "for t in range(2500):\n",
        "\n",
        "    # Прямой проход: вычисляем предсказанный y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Считаем ошибку (MSE) предскзанного y_pred и истинного y:\n",
        "    loss = (y_pred - y).pow(2).mean().item()\n",
        "    if t % 100 == 99:\n",
        "        print(f'iter={t}, loss={loss}')\n",
        "\n",
        "    # Обратный проход (вычисляем градиенты для a, b, c, d относительно loss):\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Обновляем коэффициенты полинома (веса) с учетом расчитанного градиента:\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG9sNb88T8_p",
        "outputId": "35a6626a-3b31-42b1-ce4d-f650ec4a0e1e"
      },
      "id": "MG9sNb88T8_p",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter=99, loss=1.955390214920044\n",
            "iter=199, loss=1.2952699661254883\n",
            "iter=299, loss=0.8585395812988281\n",
            "iter=399, loss=0.5695911049842834\n",
            "iter=499, loss=0.3784104287624359\n",
            "iter=599, loss=0.2519117593765259\n",
            "iter=699, loss=0.16820770502090454\n",
            "iter=799, loss=0.11281810700893402\n",
            "iter=899, loss=0.07616336643695831\n",
            "iter=999, loss=0.051905155181884766\n",
            "iter=1099, loss=0.035850223153829575\n",
            "iter=1199, loss=0.02522379718720913\n",
            "iter=1299, loss=0.018189948052167892\n",
            "iter=1399, loss=0.013533730059862137\n",
            "iter=1499, loss=0.010451221838593483\n",
            "iter=1599, loss=0.008410370908677578\n",
            "iter=1699, loss=0.007059100084006786\n",
            "iter=1799, loss=0.006164303049445152\n",
            "iter=1899, loss=0.00557170994579792\n",
            "iter=1999, loss=0.005179230123758316\n",
            "iter=2099, loss=0.004919255152344704\n",
            "iter=2199, loss=0.00474704010412097\n",
            "iter=2299, loss=0.004632928874343634\n",
            "iter=2399, loss=0.0045573171228170395\n",
            "iter=2499, loss=0.004507202189415693\n",
            "Result: y = -0.003050378058105707 + 0.8433792591094971 x + 0.0005262403865344822 x^2 + -0.09142981469631195 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch  + torch.nn + AutoGrad"
      ],
      "metadata": {
        "id": "SoJzgbh-UMXh"
      },
      "id": "SoJzgbh-UMXh"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "# Создаем датасет (x - входные данные, y - результат):\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Подготавливаем входной тензор (x, x^2, x^3) который будет поступать в сеть:\n",
        "p = torch.tensor([1, 2, 3])     # степени полинома\n",
        "xx = x.unsqueeze(-1).pow(p)     # возводим входной вектор x в степени p\n",
        "\n",
        "# Определем модель из torch.nn котора состоит из одного линейного слоя с 1 нейронам\n",
        "# каждый из трех нейронов моделирует собой один из коэффициентов полинома (а где же 4ый?)\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),      # линейный слой из одного нейрона и трех входов (весов)\n",
        "    torch.nn.Flatten(0, 1)      # представляем результат в виде вектора\n",
        ")\n",
        "\n",
        "# Функция потерь MSE из torch.nn:\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Скорость обучения:\n",
        "learning_rate = 1e-6\n",
        "\n",
        "# Оптимизационный цикл (цикл обучения):\n",
        "for t in range(2500):\n",
        "\n",
        "    # Прямой проход: вычисляем предсказанный y пропуская вход xx через модель:\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Считаем ошибку (MSE) предскзанного y_pred и истинного y:\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(f'iter={t}, loss={loss.item()}')    # !!! loss.item()\n",
        "\n",
        "    # Перед обратным проходом нам нужно занулить накопленный в буфере градиент (для всех весов)\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Обратный проход (вычисляем градиенты для весов модели относительно loss):\n",
        "    loss.backward()\n",
        "\n",
        "    # Обновляем веса модели используя градиентный спуск\n",
        "    # каждый параметр модели  (вес) является тензором,\n",
        "    # поэтому мы можем обратиться к его градиенту:\n",
        "    with torch.no_grad(): # отключаем вычисление градиента\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "\n",
        "# Мы можем обратиться к первому слою нашей модели как к первому элементу list:\n",
        "linear_layer = model[0]\n",
        "\n",
        "# Печатаем значения весов этого слоя (это и будут обученный коэффициенты искомого полинома):\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9oyWhqRUFxx",
        "outputId": "0572445e-0728-451f-b960-4262edce3c1e"
      },
      "id": "B9oyWhqRUFxx",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter=99, loss=504.31256103515625\n",
            "iter=199, loss=340.0874328613281\n",
            "iter=299, loss=230.43429565429688\n",
            "iter=399, loss=157.1763153076172\n",
            "iter=499, loss=108.20382690429688\n",
            "iter=599, loss=75.44536590576172\n",
            "iter=699, loss=53.51811218261719\n",
            "iter=799, loss=38.830810546875\n",
            "iter=899, loss=28.985736846923828\n",
            "iter=999, loss=22.381549835205078\n",
            "iter=1099, loss=17.94791030883789\n",
            "iter=1199, loss=14.968987464904785\n",
            "iter=1299, loss=12.965827941894531\n",
            "iter=1399, loss=11.617618560791016\n",
            "iter=1499, loss=10.709385871887207\n",
            "iter=1599, loss=10.09700870513916\n",
            "iter=1699, loss=9.683717727661133\n",
            "iter=1799, loss=9.404500007629395\n",
            "iter=1899, loss=9.21568489074707\n",
            "iter=1999, loss=9.087867736816406\n",
            "iter=2099, loss=9.001246452331543\n",
            "iter=2199, loss=8.942483901977539\n",
            "iter=2299, loss=8.902578353881836\n",
            "iter=2399, loss=8.875446319580078\n",
            "iter=2499, loss=8.856975555419922\n",
            "Result: y = 0.004664897453039885 + 0.8523517847061157 x + -0.0008047723094932735 x^2 + -0.09270608425140381 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten"
      ],
      "metadata": {
        "id": "qXadO7_OXYvp"
      },
      "id": "qXadO7_OXYvp"
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-мерный тензор:\n",
        "input = torch.randn(32, 1, 5, 5)\n",
        "\n",
        "# Параметры по умолчанию (0,1):\n",
        "m = torch.nn.Flatten(0, 1)\n",
        "output = m(input)\n",
        "print(output.shape)        # преобразуем в вектор только первые два измерения\n",
        "\n",
        "# Параметры (0,2):\n",
        "m = torch.nn.Flatten(0, 2)\n",
        "output = m(input)\n",
        "print(output.shape)        # преобразуем в вектор 1,2 и 3 измерения, оставля 4ое"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC-Mf8X4XWnz",
        "outputId": "f4cb8bbe-ceb7-4773-9476-e7dbb59b6f5e"
      },
      "id": "mC-Mf8X4XWnz",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5, 5])\n",
            "torch.Size([160, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch + torch.nn + AutoGrad + torch.optim"
      ],
      "metadata": {
        "id": "Ktf-xvIAXYMq"
      },
      "id": "Ktf-xvIAXYMq"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Выбираем устройства для вычислений:\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # запускаем на GPU\n",
        "\n",
        "# Создаем датасет (x - входные данные, y - результат):\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Подготавливаем входной тензор (x, x^2, x^3) который будет поступать в сеть:\n",
        "p = torch.tensor([1, 2, 3])     # степени полинома\n",
        "xx = x.unsqueeze(-1).pow(p)     # возводим входной вектор x в степени p\n",
        "\n",
        "# Определем модель из torch.nn котора состоит из одного линейного слоя с 3 нейронами\n",
        "# каждый из трех нейронов моделирует собой один из коэффициентов полинома (а где же 4ый?)\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),      # линейный слой из одного нейрона и трех входов (весов)\n",
        "    torch.nn.Flatten(0, 1)      # представляем результат в виде вектора\n",
        ")\n",
        "\n",
        "# Функция потерь MSE из torch.nn:\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Скорость обучения:\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Будем использовать оптимайзер RMSprop из torch.optim:\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# Оптимизационный цикл (цикл обучения):\n",
        "for t in range(2500):\n",
        "\n",
        "    # Прямой проход: вычисляем предсказанный y пропуская вход xx через модель:\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Считаем ошибку (MSE) предскзанного y_pred и истинного y:\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(f'iter={t}, loss={loss.item()}')    # !!! loss.item()\n",
        "\n",
        "    # Перед обратным проходом нам нужно занулить градиент для всех весов которые обновляет optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Обратный проход (вычисляем градиенты для весов модели относительно loss):\n",
        "    loss.backward()\n",
        "\n",
        "    # Обновляем веса оптимайзером:\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "# Мы можем обратиться к первому слою нашей модели как к первому элементу list:\n",
        "linear_layer = model[0]\n",
        "\n",
        "# Печатаем значения весов этого слоя (это и будут обученный коэффициенты искомого полинома):\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0QdDX-CXWlK",
        "outputId": "0fab12fa-fd9e-487d-a30c-fc9c379311d4"
      },
      "id": "f0QdDX-CXWlK",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter=99, loss=28165.541015625\n",
            "iter=199, loss=13600.197265625\n",
            "iter=299, loss=6147.93994140625\n",
            "iter=399, loss=2760.807373046875\n",
            "iter=499, loss=1645.2083740234375\n",
            "iter=599, loss=1376.6534423828125\n",
            "iter=699, loss=1221.02099609375\n",
            "iter=799, loss=1048.6444091796875\n",
            "iter=899, loss=872.923828125\n",
            "iter=999, loss=708.47705078125\n",
            "iter=1099, loss=561.4848022460938\n",
            "iter=1199, loss=433.55194091796875\n",
            "iter=1299, loss=324.5233154296875\n",
            "iter=1399, loss=233.73655700683594\n",
            "iter=1499, loss=160.3769073486328\n",
            "iter=1599, loss=103.51239776611328\n",
            "iter=1699, loss=62.07889175415039\n",
            "iter=1799, loss=34.46782302856445\n",
            "iter=1899, loss=18.61723518371582\n",
            "iter=1999, loss=11.353195190429688\n",
            "iter=2099, loss=9.18745231628418\n",
            "iter=2199, loss=8.899714469909668\n",
            "iter=2299, loss=8.925982475280762\n",
            "iter=2399, loss=8.929951667785645\n",
            "iter=2499, loss=8.916090965270996\n",
            "Result: y = -0.0004999889060854912 + 0.8571854829788208 x + -0.0004999777302145958 x^2 + -0.09283983707427979 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "фиксация весов при обучении (если необходимо)"
      ],
      "metadata": {
        "id": "KcJqCc42Zeer"
      },
      "id": "KcJqCc42Zeer"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3, 1),\n",
        "    nn.Linear(1, 1)\n",
        ")\n",
        "\n",
        "# Замораживаем только первый слой\n",
        "for param in model[0].parameters():\n",
        "    param.requires_grad = False # True - разморозка\n",
        "\n",
        "# Проверяем, какие параметры заморожены\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Параметр: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_HvayvtV8eh",
        "outputId": "290bbbf8-0640-4f55-d170-0b4754ba64ea"
      },
      "id": "m_HvayvtV8eh",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Параметр: 0.weight, requires_grad: False\n",
            "Параметр: 0.bias, requires_grad: False\n",
            "Параметр: 1.weight, requires_grad: True\n",
            "Параметр: 1.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаём оптимизатор только для обучаемых параметров\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
        "\n",
        "# Функция потерь\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "2PfD6YDxX3hf"
      },
      "id": "2PfD6YDxX3hf",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация случайных данных\n",
        "X = torch.randn(100, 3)  # 100 примеров, 10 признаков\n",
        "y = torch.randn(100, 1)   # 100 примеров, 1 целевая переменная\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(500):  # 50 эпох\n",
        "    # Forward pass\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backward pass и оптимизация\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 99 == 0:\n",
        "        print(f\"Эпоха [{epoch + 1}/{epoch}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjGt8oiOYK4i",
        "outputId": "584fee9c-8330-461f-c168-c3540aa93d33"
      },
      "id": "TjGt8oiOYK4i",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха [99/98], Loss: 0.9559\n",
            "Эпоха [198/197], Loss: 0.9559\n",
            "Эпоха [297/296], Loss: 0.9559\n",
            "Эпоха [396/395], Loss: 0.9559\n",
            "Эпоха [495/494], Loss: 0.9559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем веса первого слоя (должны остаться неизменными)\n",
        "print(\"Веса первого слоя (заморожены):\", model[0].weight)\n",
        "\n",
        "# Проверяем веса последнего слоя (должны обновиться)\n",
        "print(\"Веса последнего слоя (разморожены):\", model[1].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcWsRHUKYe8S",
        "outputId": "6db5134a-f1c3-4db4-a95d-ea1a5d5d525f"
      },
      "id": "pcWsRHUKYe8S",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Веса первого слоя (заморожены): Parameter containing:\n",
            "tensor([[ 0.1621, -0.4203, -0.4273]])\n",
            "Веса последнего слоя (разморожены): Parameter containing:\n",
            "tensor([[-0.1926]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader"
      ],
      "metadata": {
        "id": "LcNHP3D75eUa"
      },
      "id": "LcNHP3D75eUa"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Преобразования для данных\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Преобразует изображение в тензор\n",
        "])\n",
        "\n",
        "# Загрузка датасета MNIST\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Создание DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Итерация по данным\n",
        "for images, labels in dataloader:\n",
        "    print(images.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRqx9VeZ5djr",
        "outputId": "ff79c189-4405-4ecc-a78b-6e271f893766"
      },
      "id": "IRqx9VeZ5djr",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 499kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.92MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.88MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Преобразования для данных (нормализация и преобразование в тензор)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Преобразует изображение в тензор\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Нормализация (среднее и std для MNIST)\n",
        "])\n",
        "\n",
        "# Создаем собственный Dataset для MNIST\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        # Загружаем данные MNIST\n",
        "        self.data = datasets.MNIST(root=root, train=train, download=True, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Возвращаем количество изображений\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Возвращаем изображение и метку\n",
        "        image, label = self.data[idx]\n",
        "        return image, label\n",
        "\n",
        "# Создаем датасет\n",
        "train_dataset = MNISTDataset(root='./data', train=True, transform=transform)\n",
        "test_dataset = MNISTDataset(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Создаем DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # с перемешиванием\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Пример итерации (пробегаем по данным)\n",
        "for images, labels in train_loader:\n",
        "    print(\"Batch of images shape:\", images.shape)  # [batch_size, channels, height, width]\n",
        "    print(\"Batch of labels:\", labels)  # Метки для текущего батча\n",
        "\n",
        "    # Визуализация первого изображения в батче\n",
        "    plt.imshow(images[0].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Label: {labels[0]}\")\n",
        "    plt.show()\n",
        "    break  # Остановимся после первого батча для демонстрации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "ZBgsNpHr-VDj",
        "outputId": "e46f6468-2d27-42b9-807b-d617f4e7cd70"
      },
      "id": "ZBgsNpHr-VDj",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of images shape: torch.Size([64, 1, 28, 28])\n",
            "Batch of labels: tensor([5, 9, 0, 3, 0, 0, 1, 3, 4, 2, 1, 2, 4, 6, 0, 4, 3, 5, 7, 3, 0, 5, 5, 1,\n",
            "        7, 8, 7, 0, 2, 8, 0, 1, 7, 0, 4, 9, 9, 9, 0, 8, 4, 0, 1, 9, 1, 6, 3, 4,\n",
            "        5, 7, 9, 4, 8, 6, 7, 7, 2, 8, 3, 9, 3, 6, 6, 7])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIHVJREFUeJzt3XtwVPX9//HXEmBBTBZDyE1uARRULipCZEREyRBS6hjEDiqdQseBgoFyUVC0AtrORGmrVI3ITC2RIqJUgWodLBcDWrkIShkqIMFQQEhAbHa5JTDk8/uDn/t1JQFO2PBOwvMx85lhz/m897xzesyrZ8/ZE59zzgkAgEusgXUDAIDLEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQRcpN27d8vn8+kPf/hD1N6zoKBAPp9PBQUFUXtPoLYhgHBZys/Pl8/n08aNG61bqREzZsyQz+c7azRp0sS6NSCsoXUDAGrO7NmzdeWVV4Zfx8TEGHYDRCKAgHrsvvvuU0JCgnUbQKX4CA6owsmTJzVt2jT16NFDgUBAzZo10+23366PPvqoypoXXnhBbdu2VdOmTXXHHXdo69atZ83Zvn277rvvPsXHx6tJkya65ZZb9Pe///28/Rw/flzbt2/Xt99+e8E/g3NOoVBIPPQetREBBFQhFArpz3/+s/r166fnnntOM2bM0KFDh5SZmanNmzefNX/evHl68cUXlZOTo6lTp2rr1q266667VFJSEp7zn//8R7feequ2bdumxx9/XH/84x/VrFkzZWdna/HixefsZ8OGDbruuuv08ssvX/DP0L59ewUCAcXGxurnP/95RC+ANT6CA6pw1VVXaffu3WrcuHF42ciRI9W5c2e99NJLeu211yLmFxYWaufOnbr66qslSQMHDlR6erqee+45Pf/885Kk8ePHq02bNvrss8/k9/slSQ8//LD69Omjxx57TIMHD45a72PHjlXv3r3l9/v18ccfKy8vTxs2bNDGjRsVFxcXle0AF4MAAqoQExMTvmhfUVGh0tJSVVRU6JZbbtHnn39+1vzs7Oxw+EhSr169lJ6erg8++EDPP/+8vvvuO61atUrPPPOMjhw5oiNHjoTnZmZmavr06frmm28i3uOH+vXrd8EfpY0fPz7i9ZAhQ9SrVy8NGzZMr7zyih5//PELeh+gJvERHHAOr7/+urp166YmTZqoRYsWatmypf7xj38oGAyeNfeaa645a9m1116r3bt3SzpzhuSc01NPPaWWLVtGjOnTp0uSDh48WGM/y4MPPqjk5GStWLGixrYBeMEZEFCF+fPna8SIEcrOztbkyZOVmJiomJgY5ebmateuXZ7fr6KiQpL06KOPKjMzs9I5HTt2vKiez6d169b67rvvanQbwIUigIAq/O1vf1P79u317rvvyufzhZd/f7byYzt37jxr2VdffaV27dpJOnNDgCQ1atRIGRkZ0W/4PJxz2r17t2666aZLvm2gMnwEB1Th++s/P7zusn79eq1du7bS+UuWLNE333wTfr1hwwatX79eWVlZkqTExET169dPc+bM0YEDB86qP3To0Dn78XIbdmXvNXv2bB06dEgDBw48bz1wKXAGhMvaX/7yFy1btuys5ePHj9dPf/pTvfvuuxo8eLAGDRqkoqIivfrqq7r++ut19OjRs2o6duyoPn36aMyYMSovL9esWbPUokULTZkyJTwnLy9Pffr0UdeuXTVy5Ei1b99eJSUlWrt2rfbt26d///vfVfa6YcMG3XnnnZo+fbpmzJhxzp+rbdu2Gjp0qLp27aomTZrok08+0cKFC3XjjTfqV7/61YXvIKAGEUC4rM2ePbvS5SNGjNCIESNUXFysOXPm6MMPP9T111+v+fPna9GiRZU+JPQXv/iFGjRooFmzZungwYPq1auXXn75ZaWkpITnXH/99dq4caOefvpp5efn6/Dhw0pMTNRNN92kadOmRe3nGjZsmD799FO98847KisrU9u2bTVlyhQ9+eSTuuKKK6K2HeBi+BxfkQYAGOAaEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwUeu+B1RRUaH9+/crNjY24vEnAIC6wTmnI0eOKDU1VQ0aVH2eU+sCaP/+/WrdurV1GwCAi7R37161atWqyvW17iO42NhY6xYAAFFwvt/nNRZAeXl5ateunZo0aaL09HRt2LDhgur42A0A6ofz/T6vkQB66623NGnSJE2fPl2ff/65unfvrszMzBr9Y1sAgDrG1YBevXq5nJyc8OvTp0+71NRUl5ube97aYDDoJDEYDAajjo9gMHjO3/dRPwM6efKkNm3aFPEHtxo0aKCMjIxK/45KeXm5QqFQxAAA1H9RD6Bvv/1Wp0+fVlJSUsTypKQkFRcXnzU/NzdXgUAgPLgDDgAuD+Z3wU2dOlXBYDA89u7da90SAOASiPr3gBISEhQTE6OSkpKI5SUlJUpOTj5rvt/vl9/vj3YbAIBaLupnQI0bN1aPHj20cuXK8LKKigqtXLlSvXv3jvbmAAB1VI08CWHSpEkaPny4brnlFvXq1UuzZs3SsWPH9Mtf/rImNgcAqINqJICGDh2qQ4cOadq0aSouLtaNN96oZcuWnXVjAgDg8uVzzjnrJn4oFAopEAhYtwEAuEjBYFBxcXFVrje/Cw4AcHkigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJhtYNAKgfYmJiPNdMmjTJc820adM813z55Zeea6q7rQ8//LBa27occQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABA8jBeqxhg2r95/4xIkTPdf07dvXc82gQYM811RHz549q1VXUVER5U7wQ5wBAQBMEEAAABNRD6AZM2bI5/NFjM6dO0d7MwCAOq5GrgHdcMMNWrFixf9tpJqfQwMA6q8aSYaGDRsqOTm5Jt4aAFBP1Mg1oJ07dyo1NVXt27fXsGHDtGfPnirnlpeXKxQKRQwAQP0X9QBKT09Xfn6+li1bptmzZ6uoqEi33367jhw5Uun83NxcBQKB8GjdunW0WwIA1EJRD6CsrCz97Gc/U7du3ZSZmakPPvhApaWlevvttyudP3XqVAWDwfDYu3dvtFsCANRCNX53QPPmzXXttdeqsLCw0vV+v19+v7+m2wAA1DI1/j2go0ePateuXUpJSanpTQEA6pCoB9Cjjz6q1atXa/fu3fr00081ePBgxcTE6IEHHoj2pgAAdVjUP4Lbt2+fHnjgAR0+fFgtW7ZUnz59tG7dOrVs2TLamwIA1GE+55yzbuKHQqGQAoGAdRtAjarOMX7dddd5rnnyySc910iX7iGh1fG///3Pc826deuqta3s7GzPNadOnarWtuqjYDCouLi4KtfzLDgAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmavwP0gF1SePGjT3X3HzzzZ5r3nnnHc81tf1vap04ccJzzapVqzzXDB061HPN8ePHPdeg5nEGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwdOwUS8lJiZWq+6xxx7zXDNx4sRqbas2++abbzzX/PrXv/Zcs3jxYs81qD84AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCh5Gi1vP7/Z5r5s+fX61tZWRkVKvuUli1apXnmtdff71a23rvvfc815SWllZrW7h8cQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABA8jxSXVvXt3zzXPPvus55ra/FBRSXr66ac917z88sueaw4fPuy5BrhUOAMCAJgggAAAJjwH0Jo1a3T33XcrNTVVPp9PS5YsiVjvnNO0adOUkpKipk2bKiMjQzt37oxWvwCAesJzAB07dkzdu3dXXl5epetnzpypF198Ua+++qrWr1+vZs2aKTMzU2VlZRfdLACg/vB8E0JWVpaysrIqXeec06xZs/Sb3/xG99xzjyRp3rx5SkpK0pIlS3T//fdfXLcAgHojqteAioqKVFxcHHEHUiAQUHp6utauXVtpTXl5uUKhUMQAANR/UQ2g4uJiSVJSUlLE8qSkpPC6H8vNzVUgEAiP1q1bR7MlAEAtZX4X3NSpUxUMBsNj79691i0BAC6BqAZQcnKyJKmkpCRieUlJSXjdj/n9fsXFxUUMAED9F9UASktLU3JyslauXBleFgqFtH79evXu3TuamwIA1HGe74I7evSoCgsLw6+Lioq0efNmxcfHq02bNpowYYJ+97vf6ZprrlFaWpqeeuoppaamKjs7O5p9AwDqOM8BtHHjRt15553h15MmTZIkDR8+XPn5+ZoyZYqOHTumUaNGqbS0VH369NGyZcvUpEmT6HUNAKjzfM45Z93ED4VCIQUCAes2cAESExM913z22Weea+rjnZGffPKJ55p169Z5rlm4cKHnGknatm2b55oTJ05Ua1uov4LB4Dmv65vfBQcAuDwRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEzwNGxUW7t27TzXfP3119FvBFH38ccfe66ZPHmy55oNGzZ4rkHdwdOwAQC1EgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM8jBTVlpyc7Llm4cKFnmuaNWvmuaZHjx6ea3Bx/vnPf3quyc7O9lxTVlbmuQY2eBgpAKBWIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKHkaLW42Gk1ffEE09Uq27AgAFR7qRyc+bM8VwzYcIEzzXl5eWea3DxeBgpAKBWIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKHkQL1WHx8fLXqPvvsM881aWlp1dqWV6mpqZ5riouLa6ATnA8PIwUA1EoEEADAhOcAWrNmje6++26lpqbK5/NpyZIlEetHjBghn88XMQYOHBitfgEA9YTnADp27Ji6d++uvLy8KucMHDhQBw4cCI8333zzopoEANQ/Db0WZGVlKSsr65xz/H6/kpOTq90UAKD+q5FrQAUFBUpMTFSnTp00ZswYHT58uMq55eXlCoVCEQMAUP9FPYAGDhyoefPmaeXKlXruuee0evVqZWVl6fTp05XOz83NVSAQCI/WrVtHuyUAQC10Ud8D8vl8Wrx4sbKzs6uc8/XXX6tDhw5asWKF+vfvf9b68vJylZeXh1+HQiFCCIgSvgd0Bt8DsmH+PaD27dsrISFBhYWFla73+/2Ki4uLGACA+q/GA2jfvn06fPiwUlJSanpTAIA6xPNdcEePHo04mykqKtLmzZsVHx+v+Ph4Pf300xoyZIiSk5O1a9cuTZkyRR07dlRmZmZUGwcA1G2eA2jjxo268847w68nTZokSRo+fLhmz56tLVu26PXXX1dpaalSU1M1YMAA/fa3v5Xf749e1wCAOo+HkdYznTt39lyzffv2GugEddl9993nuWbu3Lmea5o1a+a55q677vJcU1BQ4LkGF8/8JgQAACpDAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDB07BrsUceecRzzahRozzXdOrUyXMN8GNfffWV55qOHTt6rsnLy/NcM27cOM81uHg8DRsAUCsRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw0dC6gctFTEyM55p+/fp5rmnRooXnGgCwwBkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEzyM9BJp2ND7rh40aJDnmu+++85zDfBjy5cv91zTrl276DeCeo0zIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZ4GOklcvLkSc81eXl5nmsefvhhzzUvvfSS5xpJGjduXLXqIA0ePNhzTd++fT3X3H///Z5rJCkhIcFzTUxMTLW25dWf/vSnS7Id1DzOgAAAJgggAIAJTwGUm5urnj17KjY2VomJicrOztaOHTsi5pSVlSknJ0ctWrTQlVdeqSFDhqikpCSqTQMA6j5PAbR69Wrl5ORo3bp1Wr58uU6dOqUBAwbo2LFj4TkTJ07Ue++9p0WLFmn16tXav3+/7r333qg3DgCo2zzdhLBs2bKI1/n5+UpMTNSmTZvUt29fBYNBvfbaa1qwYIHuuusuSdLcuXN13XXXad26dbr11luj1zkAoE67qGtAwWBQkhQfHy9J2rRpk06dOqWMjIzwnM6dO6tNmzZau3Ztpe9RXl6uUCgUMQAA9V+1A6iiokITJkzQbbfdpi5dukiSiouL1bhxYzVv3jxiblJSkoqLiyt9n9zcXAUCgfBo3bp1dVsCANQh1Q6gnJwcbd26VQsXLryoBqZOnapgMBgee/fuvaj3AwDUDdX6IurYsWP1/vvva82aNWrVqlV4eXJysk6ePKnS0tKIs6CSkhIlJydX+l5+v19+v786bQAA6jBPZ0DOOY0dO1aLFy/WqlWrlJaWFrG+R48eatSokVauXBletmPHDu3Zs0e9e/eOTscAgHrB0xlQTk6OFixYoKVLlyo2NjZ8XScQCKhp06YKBAJ66KGHNGnSJMXHxysuLk7jxo1T7969uQMOABDBUwDNnj1bktSvX7+I5XPnztWIESMkSS+88IIaNGigIUOGqLy8XJmZmXrllVei0iwAoP7wOeecdRM/FAqFFAgErNuoFYYMGeK5ZtGiRZ5rqnsIlJaWeq5ZsmSJ55qtW7d6rqmu6jy8s2PHjp5rYmNjPdc0bFi7nx28bds2zzWDBg3yXLNnzx7PNRUVFZ5rcPGCwaDi4uKqXM+z4AAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJngadi3m8/k81zz44IOea/761796rkHdkJ+fX626Z555xnPN938fzIuysjLPNag7eBo2AKBWIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKHkdYz1XmA6VVXXVWtbU2YMOGSbGvs2LGea95++23PNZK0Y8eOatV5NW/ePM81e/bs8Vxz6tQpzzWSVMt+LaCO4mGkAIBaiQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkeRgoAqBE8jBQAUCsRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCEpwDKzc1Vz549FRsbq8TERGVnZ2vHjh0Rc/r16yefzxcxRo8eHdWmAQB1n6cAWr16tXJycrRu3TotX75cp06d0oABA3Ts2LGIeSNHjtSBAwfCY+bMmVFtGgBQ9zX0MnnZsmURr/Pz85WYmKhNmzapb9++4eVXXHGFkpOTo9MhAKBeuqhrQMFgUJIUHx8fsfyNN95QQkKCunTpoqlTp+r48eNVvkd5eblCoVDEAABcBlw1nT592g0aNMjddtttEcvnzJnjli1b5rZs2eLmz5/vrr76ajd48OAq32f69OlOEoPBYDDq2QgGg+fMkWoH0OjRo13btm3d3r17zzlv5cqVTpIrLCysdH1ZWZkLBoPhsXfvXvOdxmAwGIyLH+cLIE/XgL43duxYvf/++1qzZo1atWp1zrnp6emSpMLCQnXo0OGs9X6/X36/vzptAADqME8B5JzTuHHjtHjxYhUUFCgtLe28NZs3b5YkpaSkVKtBAED95CmAcnJytGDBAi1dulSxsbEqLi6WJAUCATVt2lS7du3SggUL9JOf/EQtWrTQli1bNHHiRPXt21fdunWrkR8AAFBHebnuoyo+55s7d65zzrk9e/a4vn37uvj4eOf3+13Hjh3d5MmTz/s54A8Fg0Hzzy0ZDAaDcfHjfL/7ff8/WGqNUCikQCBg3QYA4CIFg0HFxcVVuZ5nwQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATNS6AHLOWbcAAIiC8/0+r3UBdOTIEesWAABRcL7f5z5Xy045KioqtH//fsXGxsrn80WsC4VCat26tfbu3au4uDijDu2xH85gP5zBfjiD/XBGbdgPzjkdOXJEqampatCg6vOchpewpwvSoEEDtWrV6pxz4uLiLusD7HvshzPYD2ewH85gP5xhvR8CgcB559S6j+AAAJcHAggAYKJOBZDf79f06dPl9/utWzHFfjiD/XAG++EM9sMZdWk/1LqbEAAAl4c6dQYEAKg/CCAAgAkCCABgggACAJgggAAAJupMAOXl5aldu3Zq0qSJ0tPTtWHDBuuWLrkZM2bI5/NFjM6dO1u3VePWrFmju+++W6mpqfL5fFqyZEnEeuecpk2bppSUFDVt2lQZGRnauXOnTbM16Hz7YcSIEWcdHwMHDrRptobk5uaqZ8+eio2NVWJiorKzs7Vjx46IOWVlZcrJyVGLFi105ZVXasiQISopKTHquGZcyH7o16/fWcfD6NGjjTquXJ0IoLfeekuTJk3S9OnT9fnnn6t79+7KzMzUwYMHrVu75G644QYdOHAgPD755BPrlmrcsWPH1L17d+Xl5VW6fubMmXrxxRf16quvav369WrWrJkyMzNVVlZ2iTutWefbD5I0cODAiOPjzTffvIQd1rzVq1crJydH69at0/Lly3Xq1CkNGDBAx44dC8+ZOHGi3nvvPS1atEirV6/W/v37de+99xp2HX0Xsh8kaeTIkRHHw8yZM406roKrA3r16uVycnLCr0+fPu1SU1Ndbm6uYVeX3vTp01337t2t2zAlyS1evDj8uqKiwiUnJ7vf//734WWlpaXO7/e7N99806DDS+PH+8E554YPH+7uuecek36sHDx40Elyq1evds6d+d++UaNGbtGiReE527Ztc5Lc2rVrrdqscT/eD845d8cdd7jx48fbNXUBav0Z0MmTJ7Vp0yZlZGSElzVo0EAZGRlau3atYWc2du7cqdTUVLVv317Dhg3Tnj17rFsyVVRUpOLi4ojjIxAIKD09/bI8PgoKCpSYmKhOnTppzJgxOnz4sHVLNSoYDEqS4uPjJUmbNm3SqVOnIo6Hzp07q02bNvX6ePjxfvjeG2+8oYSEBHXp0kVTp07V8ePHLdqrUq17GvaPffvttzp9+rSSkpIiliclJWn79u1GXdlIT09Xfn6+OnXqpAMHDujpp5/W7bffrq1btyo2Nta6PRPFxcWSVOnx8f26y8XAgQN17733Ki0tTbt27dITTzyhrKwsrV27VjExMdbtRV1FRYUmTJig2267TV26dJF05nho3LixmjdvHjG3Ph8Ple0HSXrwwQfVtm1bpaamasuWLXrssce0Y8cOvfvuu4bdRqr1AYT/k5WVFf53t27dlJ6errZt2+rtt9/WQw89ZNgZaoP7778//O+uXbuqW7du6tChgwoKCtS/f3/DzmpGTk6Otm7dellcBz2XqvbDqFGjwv/u2rWrUlJS1L9/f+3atUsdOnS41G1WqtZ/BJeQkKCYmJiz7mIpKSlRcnKyUVe1Q/PmzXXttdeqsLDQuhUz3x8DHB9na9++vRISEurl8TF27Fi9//77+uijjyL+flhycrJOnjyp0tLSiPn19Xioaj9UJj09XZJq1fFQ6wOocePG6tGjh1auXBleVlFRoZUrV6p3796Gndk7evSodu3apZSUFOtWzKSlpSk5OTni+AiFQlq/fv1lf3zs27dPhw8frlfHh3NOY8eO1eLFi7Vq1SqlpaVFrO/Ro4caNWoUcTzs2LFDe/bsqVfHw/n2Q2U2b94sSbXreLC+C+JCLFy40Pn9fpefn+++/PJLN2rUKNe8eXNXXFxs3dol9cgjj7iCggJXVFTk/vWvf7mMjAyXkJDgDh48aN1ajTpy5Ij74osv3BdffOEkueeff9598cUX7r///a9zzrlnn33WNW/e3C1dutRt2bLF3XPPPS4tLc2dOHHCuPPoOtd+OHLkiHv00Ufd2rVrXVFRkVuxYoW7+eab3TXXXOPKysqsW4+aMWPGuEAg4AoKCtyBAwfC4/jx4+E5o0ePdm3atHGrVq1yGzdudL1793a9e/c27Dr6zrcfCgsL3TPPPOM2btzoioqK3NKlS1379u1d3759jTuPVCcCyDnnXnrpJdemTRvXuHFj16tXL7du3Trrli65oUOHupSUFNe4cWN39dVXu6FDh7rCwkLrtmrcRx995CSdNYYPH+6cO3Mr9lNPPeWSkpKc3+93/fv3dzt27LBtugacaz8cP37cDRgwwLVs2dI1atTItW3b1o0cObLe/Z+0yn5+SW7u3LnhOSdOnHAPP/ywu+qqq9wVV1zhBg8e7A4cOGDXdA04337Ys2eP69u3r4uPj3d+v9917NjRTZ482QWDQdvGf4S/BwQAMFHrrwEBAOonAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4f3NCiyTJOhsbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}